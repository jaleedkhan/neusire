{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd4eb6c6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jaleed/Jaleed/SGG/Scene\n",
      "2408978.jpg\n",
      "2022-08-10 17:51:08,713 maskrcnn_benchmark INFO: Using 1 GPUs\n",
      "2022-08-10 17:51:08,713 maskrcnn_benchmark INFO: AMP_VERBOSE: False\n",
      "DATALOADER:\n",
      "  ASPECT_RATIO_GROUPING: True\n",
      "  NUM_WORKERS: 4\n",
      "  SIZE_DIVISIBILITY: 32\n",
      "DATASETS:\n",
      "  TEST: ('VG_stanford_filtered_with_attribute_test',)\n",
      "  TO_TEST: None\n",
      "  TRAIN: ('VG_stanford_filtered_with_attribute_train',)\n",
      "  VAL: ('VG_stanford_filtered_with_attribute_val',)\n",
      "DETECTED_SGG_DIR: /home/jaleed/Jaleed/SGG/temp_dir_out\n",
      "DTYPE: float16\n",
      "GLOVE_DIR: /home/jaleed/Jaleed/SGG/glove\n",
      "INPUT:\n",
      "  BRIGHTNESS: 0.0\n",
      "  CONTRAST: 0.0\n",
      "  HUE: 0.0\n",
      "  MAX_SIZE_TEST: 1000\n",
      "  MAX_SIZE_TRAIN: 1000\n",
      "  MIN_SIZE_TEST: 600\n",
      "  MIN_SIZE_TRAIN: (600,)\n",
      "  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]\n",
      "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
      "  SATURATION: 0.0\n",
      "  TO_BGR255: True\n",
      "  VERTICAL_FLIP_PROB_TRAIN: 0.0\n",
      "MODEL:\n",
      "  ATTRIBUTE_ON: False\n",
      "  BACKBONE:\n",
      "    CONV_BODY: R-101-FPN\n",
      "    FREEZE_CONV_BODY_AT: 2\n",
      "  CLS_AGNOSTIC_BBOX_REG: False\n",
      "  DEVICE: cuda\n",
      "  FBNET:\n",
      "    ARCH: default\n",
      "    ARCH_DEF: \n",
      "    BN_TYPE: bn\n",
      "    DET_HEAD_BLOCKS: []\n",
      "    DET_HEAD_LAST_SCALE: 1.0\n",
      "    DET_HEAD_STRIDE: 0\n",
      "    DW_CONV_SKIP_BN: True\n",
      "    DW_CONV_SKIP_RELU: True\n",
      "    KPTS_HEAD_BLOCKS: []\n",
      "    KPTS_HEAD_LAST_SCALE: 0.0\n",
      "    KPTS_HEAD_STRIDE: 0\n",
      "    MASK_HEAD_BLOCKS: []\n",
      "    MASK_HEAD_LAST_SCALE: 0.0\n",
      "    MASK_HEAD_STRIDE: 0\n",
      "    RPN_BN_TYPE: \n",
      "    RPN_HEAD_BLOCKS: 0\n",
      "    SCALE_FACTOR: 1.0\n",
      "    WIDTH_DIVISOR: 1\n",
      "  FLIP_AUG: False\n",
      "  FPN:\n",
      "    USE_GN: False\n",
      "    USE_RELU: False\n",
      "  GROUP_NORM:\n",
      "    DIM_PER_GP: -1\n",
      "    EPSILON: 1e-05\n",
      "    NUM_GROUPS: 32\n",
      "  KEYPOINT_ON: False\n",
      "  MASK_ON: False\n",
      "  META_ARCHITECTURE: GeneralizedRCNN\n",
      "  PRETRAINED_DETECTOR_CKPT: /home/jaleed/Jaleed/SGG/checkpoint/upload_causal_motif_sgdet\n",
      "  RELATION_ON: True\n",
      "  RESNETS:\n",
      "    BACKBONE_OUT_CHANNELS: 256\n",
      "    DEFORMABLE_GROUPS: 1\n",
      "    NUM_GROUPS: 32\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    RES5_DILATION: 1\n",
      "    STAGE_WITH_DCN: (False, False, False, False)\n",
      "    STEM_FUNC: StemWithFixedBatchNorm\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "    STRIDE_IN_1X1: False\n",
      "    TRANS_FUNC: BottleneckWithFixedBatchNorm\n",
      "    WIDTH_PER_GROUP: 8\n",
      "    WITH_MODULATED_DCN: False\n",
      "  RETINANET:\n",
      "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
      "    ANCHOR_STRIDES: (8, 16, 32, 64, 128)\n",
      "    ASPECT_RATIOS: (0.5, 1.0, 2.0)\n",
      "    BBOX_REG_BETA: 0.11\n",
      "    BBOX_REG_WEIGHT: 4.0\n",
      "    BG_IOU_THRESHOLD: 0.4\n",
      "    FG_IOU_THRESHOLD: 0.5\n",
      "    INFERENCE_TH: 0.05\n",
      "    LOSS_ALPHA: 0.25\n",
      "    LOSS_GAMMA: 2.0\n",
      "    NMS_TH: 0.4\n",
      "    NUM_CLASSES: 81\n",
      "    NUM_CONVS: 4\n",
      "    OCTAVE: 2.0\n",
      "    PRE_NMS_TOP_N: 1000\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCALES_PER_OCTAVE: 3\n",
      "    STRADDLE_THRESH: 0\n",
      "    USE_C5: True\n",
      "  RETINANET_ON: False\n",
      "  ROI_ATTRIBUTE_HEAD:\n",
      "    ATTRIBUTE_BGFG_RATIO: 3\n",
      "    ATTRIBUTE_BGFG_SAMPLE: True\n",
      "    ATTRIBUTE_LOSS_WEIGHT: 1.0\n",
      "    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor\n",
      "    MAX_ATTRIBUTES: 10\n",
      "    NUM_ATTRIBUTES: 201\n",
      "    POS_WEIGHT: 50.0\n",
      "    PREDICTOR: FPNPredictor\n",
      "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
      "    USE_BINARY_LOSS: True\n",
      "  ROI_BOX_HEAD:\n",
      "    CONV_HEAD_DIM: 256\n",
      "    DILATION: 1\n",
      "    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor\n",
      "    MLP_HEAD_DIM: 4096\n",
      "    NUM_CLASSES: 151\n",
      "    NUM_STACKED_CONVS: 4\n",
      "    POOLER_RESOLUTION: 7\n",
      "    POOLER_SAMPLING_RATIO: 2\n",
      "    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)\n",
      "    PREDICTOR: FPNPredictor\n",
      "    USE_GN: False\n",
      "  ROI_HEADS:\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
      "    BG_IOU_THRESHOLD: 0.3\n",
      "    DETECTIONS_PER_IMG: 80\n",
      "    FG_IOU_THRESHOLD: 0.5\n",
      "    NMS: 0.3\n",
      "    NMS_FILTER_DUPLICATES: True\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_PER_CLS_TOPN: 300\n",
      "    SCORE_THRESH: 0.01\n",
      "    USE_FPN: True\n",
      "  ROI_KEYPOINT_HEAD:\n",
      "    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
      "    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor\n",
      "    MLP_HEAD_DIM: 1024\n",
      "    NUM_CLASSES: 17\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_SCALES: (0.0625,)\n",
      "    PREDICTOR: KeypointRCNNPredictor\n",
      "    RESOLUTION: 14\n",
      "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
      "  ROI_MASK_HEAD:\n",
      "    CONV_LAYERS: (256, 256, 256, 256)\n",
      "    DILATION: 1\n",
      "    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor\n",
      "    MLP_HEAD_DIM: 1024\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_SCALES: (0.0625,)\n",
      "    POSTPROCESS_MASKS: False\n",
      "    POSTPROCESS_MASKS_THRESHOLD: 0.5\n",
      "    PREDICTOR: MaskRCNNC4Predictor\n",
      "    RESOLUTION: 14\n",
      "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
      "    USE_GN: False\n",
      "  ROI_RELATION_HEAD:\n",
      "    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True\n",
      "    BATCH_SIZE_PER_IMAGE: 1024\n",
      "    CAUSAL:\n",
      "      CONTEXT_LAYER: motifs\n",
      "      EFFECT_ANALYSIS: True\n",
      "      EFFECT_TYPE: none\n",
      "      FUSION_TYPE: sum\n",
      "      SEPARATE_SPATIAL: False\n",
      "      SPATIAL_FOR_VISION: True\n",
      "    CONTEXT_DROPOUT_RATE: 0.2\n",
      "    CONTEXT_HIDDEN_DIM: 512\n",
      "    CONTEXT_OBJ_LAYER: 1\n",
      "    CONTEXT_POOLING_DIM: 4096\n",
      "    CONTEXT_REL_LAYER: 1\n",
      "    EMBED_DIM: 200\n",
      "    FEATURE_EXTRACTOR: RelationFeatureExtractor\n",
      "    LABEL_SMOOTHING_LOSS: False\n",
      "    NUM_CLASSES: 51\n",
      "    NUM_SAMPLE_PER_GT_REL: 4\n",
      "    POOLING_ALL_LEVELS: True\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    PREDICTOR: CausalAnalysisPredictor\n",
      "    PREDICT_USE_BIAS: True\n",
      "    PREDICT_USE_VISION: True\n",
      "    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]\n",
      "    REQUIRE_BOX_OVERLAP: False\n",
      "    TRANSFORMER:\n",
      "      DROPOUT_RATE: 0.1\n",
      "      INNER_DIM: 2048\n",
      "      KEY_DIM: 64\n",
      "      NUM_HEAD: 8\n",
      "      OBJ_LAYER: 4\n",
      "      REL_LAYER: 2\n",
      "      VAL_DIM: 64\n",
      "    USE_GT_BOX: False\n",
      "    USE_GT_OBJECT_LABEL: False\n",
      "  RPN:\n",
      "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
      "    ANCHOR_STRIDE: (4, 8, 16, 32, 64)\n",
      "    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BG_IOU_THRESHOLD: 0.3\n",
      "    FG_IOU_THRESHOLD: 0.7\n",
      "    FPN_POST_NMS_PER_BATCH: False\n",
      "    FPN_POST_NMS_TOP_N_TEST: 1000\n",
      "    FPN_POST_NMS_TOP_N_TRAIN: 1000\n",
      "    MIN_SIZE: 0\n",
      "    NMS_THRESH: 0.7\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_TOP_N_TEST: 1000\n",
      "    POST_NMS_TOP_N_TRAIN: 1000\n",
      "    PRE_NMS_TOP_N_TEST: 6000\n",
      "    PRE_NMS_TOP_N_TRAIN: 6000\n",
      "    RPN_HEAD: SingleConvRPNHead\n",
      "    RPN_MID_CHANNEL: 256\n",
      "    STRADDLE_THRESH: 0\n",
      "    USE_FPN: True\n",
      "  RPN_ONLY: False\n",
      "  VGG:\n",
      "    VGG16_OUT_CHANNELS: 512\n",
      "  WEIGHT: catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d\n",
      "OUTPUT_DIR: /home/jaleed/Jaleed/SGG/checkpoint/upload_causal_motif_sgdet\n",
      "PATHS_CATALOG: /home/jaleed/Jaleed/SGG/Scene/maskrcnn_benchmark/config/paths_catalog.py\n",
      "PATHS_DATA: /home/jaleed/Jaleed/SGG/Scene/maskrcnn_benchmark/config/../data/datasets\n",
      "SOLVER:\n",
      "  BASE_LR: 0.01\n",
      "  BIAS_LR_FACTOR: 1\n",
      "  CHECKPOINT_PERIOD: 2000\n",
      "  CLIP_NORM: 5.0\n",
      "  GAMMA: 0.1\n",
      "  GRAD_NORM_CLIP: 5.0\n",
      "  IMS_PER_BATCH: 16\n",
      "  MAX_ITER: 40000\n",
      "  MOMENTUM: 0.9\n",
      "  PRE_VAL: True\n",
      "  PRINT_GRAD_FREQ: 4000\n",
      "  SCHEDULE:\n",
      "    COOLDOWN: 0\n",
      "    FACTOR: 0.1\n",
      "    MAX_DECAY_STEP: 3\n",
      "    PATIENCE: 2\n",
      "    THRESHOLD: 0.001\n",
      "    TYPE: WarmupReduceLROnPlateau\n",
      "  STEPS: (10000, 16000)\n",
      "  TO_VAL: True\n",
      "  UPDATE_SCHEDULE_DURING_LOAD: False\n",
      "  VAL_PERIOD: 2000\n",
      "  WARMUP_FACTOR: 0.1\n",
      "  WARMUP_ITERS: 500\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: 0.0\n",
      "TEST:\n",
      "  ALLOW_LOAD_FROM_CACHE: False\n",
      "  BBOX_AUG:\n",
      "    ENABLED: False\n",
      "    H_FLIP: False\n",
      "    MAX_SIZE: 4000\n",
      "    SCALES: ()\n",
      "    SCALE_H_FLIP: False\n",
      "  CUSTUM_EVAL: True\n",
      "  CUSTUM_PATH: /home/jaleed/Jaleed/SGG/temp_dir_inp\n",
      "  DETECTIONS_PER_IMG: 100\n",
      "  EXPECTED_RESULTS: []\n",
      "  EXPECTED_RESULTS_SIGMA_TOL: 4\n",
      "  IMS_PER_BATCH: 1\n",
      "  RELATION:\n",
      "    IOU_THRESHOLD: 0.5\n",
      "    LATER_NMS_PREDICTION_THRES: 0.5\n",
      "    MULTIPLE_PREDS: False\n",
      "    REQUIRE_OVERLAP: False\n",
      "    SYNC_GATHER: True\n",
      "  SAVE_PROPOSALS: False\n",
      "2022-08-10 17:51:08,714 maskrcnn_benchmark INFO: Collecting env info (might take some time)\n",
      "2022-08-10 17:51:15,811 maskrcnn_benchmark INFO: \n",
      "PyTorch version: 1.4.0\n",
      "Is debug build: No\n",
      "CUDA used to build PyTorch: 10.1\n",
      "\n",
      "OS: Ubuntu 18.04.6 LTS\n",
      "GCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
      "CMake version: version 3.10.2\n",
      "\n",
      "Python version: 3.7\n",
      "Is CUDA available: Yes\n",
      "CUDA runtime version: 10.1.105\n",
      "GPU models and configuration: GPU 0: TITAN Xp\n",
      "Nvidia driver version: 440.33.01\n",
      "cuDNN version: Could not collect\n",
      "\n",
      "Versions of relevant libraries:\n",
      "[pip3] numpy==1.21.5\n",
      "[pip3] torch==1.4.0\n",
      "[pip3] torchtext==0.4.0\n",
      "[pip3] torchvision==0.5.0\n",
      "[conda] blas                      1.0                         mkl  \n",
      "[conda] mkl                       2021.4.0           h06a4308_640  \n",
      "[conda] mkl-service               2.4.0            py37h7f8727e_0  \n",
      "[conda] mkl_fft                   1.3.1            py37hd3c417c_0  \n",
      "[conda] mkl_random                1.2.2            py37h51133e4_0  \n",
      "[conda] pytorch                   1.4.0           py3.7_cuda10.1.243_cudnn7.6.3_0    pytorch\n",
      "[conda] torchtext                 0.4.0                    pypi_0    pypi\n",
      "[conda] torchvision               0.5.0                py37_cu101    pytorch\n",
      "        Pillow (9.2.0)\n",
      "2022-08-10 17:51:19,328 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------\n",
      "2022-08-10 17:51:19,328 maskrcnn_benchmark.data.build INFO: get dataset statistics...\n",
      "2022-08-10 17:51:19,352 maskrcnn_benchmark.data.build INFO: Loading data statistics from: /home/jaleed/Jaleed/SGG/checkpoint/upload_causal_motif_sgdet/VG_stanford_filtered_with_attribute_train_statistics.cache\n",
      "2022-08-10 17:51:19,353 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------\n",
      "loading word vectors from /home/jaleed/Jaleed/SGG/glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "loading word vectors from /home/jaleed/Jaleed/SGG/glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "INIT SAVE DIR /home/jaleed/Jaleed/SGG/checkpoint/upload_causal_motif_sgdet\n",
      "get_checkpoint_file /home/jaleed/Jaleed/SGG/checkpoint/upload_causal_motif_sgdet/last_checkpoint\n",
      "last_saved /home/jaleed/Jaleed/SGG/checkpoint/upload_causal_motif_sgdet/model_0028000.pth\n",
      "2022-08-10 17:51:32,664 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from /home/jaleed/Jaleed/SGG/checkpoint/upload_causal_motif_sgdet/model_0028000.pth\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 12.43it/s]\n",
      "=====> /home/jaleed/Jaleed/SGG/temp_dir_out/custom_data_info.json SAVED !\n",
      "2022-08-10 17:51:46,745 maskrcnn_benchmark.inference INFO: Start evaluation on VG_stanford_filtered_with_attribute_test dataset(1 images).\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.96s/it]\n",
      "2022-08-10 17:51:48,784 maskrcnn_benchmark.inference INFO: Total run time: 0:00:02.038150 (2.0381503105163574 s / img per device, on 1 devices)\n",
      "2022-08-10 17:51:48,784 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.612810 (1.6128103733062744 s / img per device, on 1 devices)\n",
      "=====> /home/jaleed/Jaleed/SGG/temp_dir_out/custom_prediction.json SAVED !\n",
      "/home/jaleed/Jaleed/SGG/Scene\n",
      "2402809.jpg\n",
      "2022-08-10 17:51:55,805 maskrcnn_benchmark INFO: Using 1 GPUs\n",
      "2022-08-10 17:51:55,805 maskrcnn_benchmark INFO: AMP_VERBOSE: False\n",
      "DATALOADER:\n",
      "  ASPECT_RATIO_GROUPING: True\n",
      "  NUM_WORKERS: 4\n",
      "  SIZE_DIVISIBILITY: 32\n",
      "DATASETS:\n",
      "  TEST: ('VG_stanford_filtered_with_attribute_test',)\n",
      "  TO_TEST: None\n",
      "  TRAIN: ('VG_stanford_filtered_with_attribute_train',)\n",
      "  VAL: ('VG_stanford_filtered_with_attribute_val',)\n",
      "DETECTED_SGG_DIR: /home/jaleed/Jaleed/SGG/temp_dir_out\n",
      "DTYPE: float16\n",
      "GLOVE_DIR: /home/jaleed/Jaleed/SGG/glove\n",
      "INPUT:\n",
      "  BRIGHTNESS: 0.0\n",
      "  CONTRAST: 0.0\n",
      "  HUE: 0.0\n",
      "  MAX_SIZE_TEST: 1000\n",
      "  MAX_SIZE_TRAIN: 1000\n",
      "  MIN_SIZE_TEST: 600\n",
      "  MIN_SIZE_TRAIN: (600,)\n",
      "  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]\n",
      "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
      "  SATURATION: 0.0\n",
      "  TO_BGR255: True\n",
      "  VERTICAL_FLIP_PROB_TRAIN: 0.0\n",
      "MODEL:\n",
      "  ATTRIBUTE_ON: False\n",
      "  BACKBONE:\n",
      "    CONV_BODY: R-101-FPN\n",
      "    FREEZE_CONV_BODY_AT: 2\n",
      "  CLS_AGNOSTIC_BBOX_REG: False\n",
      "  DEVICE: cuda\n",
      "  FBNET:\n",
      "    ARCH: default\n",
      "    ARCH_DEF: \n",
      "    BN_TYPE: bn\n",
      "    DET_HEAD_BLOCKS: []\n",
      "    DET_HEAD_LAST_SCALE: 1.0\n",
      "    DET_HEAD_STRIDE: 0\n",
      "    DW_CONV_SKIP_BN: True\n",
      "    DW_CONV_SKIP_RELU: True\n",
      "    KPTS_HEAD_BLOCKS: []\n",
      "    KPTS_HEAD_LAST_SCALE: 0.0\n",
      "    KPTS_HEAD_STRIDE: 0\n",
      "    MASK_HEAD_BLOCKS: []\n",
      "    MASK_HEAD_LAST_SCALE: 0.0\n",
      "    MASK_HEAD_STRIDE: 0\n",
      "    RPN_BN_TYPE: \n",
      "    RPN_HEAD_BLOCKS: 0\n",
      "    SCALE_FACTOR: 1.0\n",
      "    WIDTH_DIVISOR: 1\n",
      "  FLIP_AUG: False\n",
      "  FPN:\n",
      "    USE_GN: False\n",
      "    USE_RELU: False\n",
      "  GROUP_NORM:\n",
      "    DIM_PER_GP: -1\n",
      "    EPSILON: 1e-05\n",
      "    NUM_GROUPS: 32\n",
      "  KEYPOINT_ON: False\n",
      "  MASK_ON: False\n",
      "  META_ARCHITECTURE: GeneralizedRCNN\n",
      "  PRETRAINED_DETECTOR_CKPT: /home/jaleed/Jaleed/SGG/checkpoint/upload_causal_motif_sgdet\n",
      "  RELATION_ON: True\n",
      "  RESNETS:\n",
      "    BACKBONE_OUT_CHANNELS: 256\n",
      "    DEFORMABLE_GROUPS: 1\n",
      "    NUM_GROUPS: 32\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    RES5_DILATION: 1\n",
      "    STAGE_WITH_DCN: (False, False, False, False)\n",
      "    STEM_FUNC: StemWithFixedBatchNorm\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "    STRIDE_IN_1X1: False\n",
      "    TRANS_FUNC: BottleneckWithFixedBatchNorm\n",
      "    WIDTH_PER_GROUP: 8\n",
      "    WITH_MODULATED_DCN: False\n",
      "  RETINANET:\n",
      "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
      "    ANCHOR_STRIDES: (8, 16, 32, 64, 128)\n",
      "    ASPECT_RATIOS: (0.5, 1.0, 2.0)\n",
      "    BBOX_REG_BETA: 0.11\n",
      "    BBOX_REG_WEIGHT: 4.0\n",
      "    BG_IOU_THRESHOLD: 0.4\n",
      "    FG_IOU_THRESHOLD: 0.5\n",
      "    INFERENCE_TH: 0.05\n",
      "    LOSS_ALPHA: 0.25\n",
      "    LOSS_GAMMA: 2.0\n",
      "    NMS_TH: 0.4\n",
      "    NUM_CLASSES: 81\n",
      "    NUM_CONVS: 4\n",
      "    OCTAVE: 2.0\n",
      "    PRE_NMS_TOP_N: 1000\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCALES_PER_OCTAVE: 3\n",
      "    STRADDLE_THRESH: 0\n",
      "    USE_C5: True\n",
      "  RETINANET_ON: False\n",
      "  ROI_ATTRIBUTE_HEAD:\n",
      "    ATTRIBUTE_BGFG_RATIO: 3\n",
      "    ATTRIBUTE_BGFG_SAMPLE: True\n",
      "    ATTRIBUTE_LOSS_WEIGHT: 1.0\n",
      "    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor\n",
      "    MAX_ATTRIBUTES: 10\n",
      "    NUM_ATTRIBUTES: 201\n",
      "    POS_WEIGHT: 50.0\n",
      "    PREDICTOR: FPNPredictor\n",
      "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
      "    USE_BINARY_LOSS: True\n",
      "  ROI_BOX_HEAD:\n",
      "    CONV_HEAD_DIM: 256\n",
      "    DILATION: 1\n",
      "    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor\n",
      "    MLP_HEAD_DIM: 4096\n",
      "    NUM_CLASSES: 151\n",
      "    NUM_STACKED_CONVS: 4\n",
      "    POOLER_RESOLUTION: 7\n",
      "    POOLER_SAMPLING_RATIO: 2\n",
      "    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)\n",
      "    PREDICTOR: FPNPredictor\n",
      "    USE_GN: False\n",
      "  ROI_HEADS:\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
      "    BG_IOU_THRESHOLD: 0.3\n",
      "    DETECTIONS_PER_IMG: 80\n",
      "    FG_IOU_THRESHOLD: 0.5\n",
      "    NMS: 0.3\n",
      "    NMS_FILTER_DUPLICATES: True\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_PER_CLS_TOPN: 300\n",
      "    SCORE_THRESH: 0.01\n",
      "    USE_FPN: True\n",
      "  ROI_KEYPOINT_HEAD:\n",
      "    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
      "    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor\n",
      "    MLP_HEAD_DIM: 1024\n",
      "    NUM_CLASSES: 17\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_SCALES: (0.0625,)\n",
      "    PREDICTOR: KeypointRCNNPredictor\n",
      "    RESOLUTION: 14\n",
      "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
      "  ROI_MASK_HEAD:\n",
      "    CONV_LAYERS: (256, 256, 256, 256)\n",
      "    DILATION: 1\n",
      "    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor\n",
      "    MLP_HEAD_DIM: 1024\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_SCALES: (0.0625,)\n",
      "    POSTPROCESS_MASKS: False\n",
      "    POSTPROCESS_MASKS_THRESHOLD: 0.5\n",
      "    PREDICTOR: MaskRCNNC4Predictor\n",
      "    RESOLUTION: 14\n",
      "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
      "    USE_GN: False\n",
      "  ROI_RELATION_HEAD:\n",
      "    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True\n",
      "    BATCH_SIZE_PER_IMAGE: 1024\n",
      "    CAUSAL:\n",
      "      CONTEXT_LAYER: motifs\n",
      "      EFFECT_ANALYSIS: True\n",
      "      EFFECT_TYPE: none\n",
      "      FUSION_TYPE: sum\n",
      "      SEPARATE_SPATIAL: False\n",
      "      SPATIAL_FOR_VISION: True\n",
      "    CONTEXT_DROPOUT_RATE: 0.2\n",
      "    CONTEXT_HIDDEN_DIM: 512\n",
      "    CONTEXT_OBJ_LAYER: 1\n",
      "    CONTEXT_POOLING_DIM: 4096\n",
      "    CONTEXT_REL_LAYER: 1\n",
      "    EMBED_DIM: 200\n",
      "    FEATURE_EXTRACTOR: RelationFeatureExtractor\n",
      "    LABEL_SMOOTHING_LOSS: False\n",
      "    NUM_CLASSES: 51\n",
      "    NUM_SAMPLE_PER_GT_REL: 4\n",
      "    POOLING_ALL_LEVELS: True\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    PREDICTOR: CausalAnalysisPredictor\n",
      "    PREDICT_USE_BIAS: True\n",
      "    PREDICT_USE_VISION: True\n",
      "    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]\n",
      "    REQUIRE_BOX_OVERLAP: False\n",
      "    TRANSFORMER:\n",
      "      DROPOUT_RATE: 0.1\n",
      "      INNER_DIM: 2048\n",
      "      KEY_DIM: 64\n",
      "      NUM_HEAD: 8\n",
      "      OBJ_LAYER: 4\n",
      "      REL_LAYER: 2\n",
      "      VAL_DIM: 64\n",
      "    USE_GT_BOX: False\n",
      "    USE_GT_OBJECT_LABEL: False\n",
      "  RPN:\n",
      "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
      "    ANCHOR_STRIDE: (4, 8, 16, 32, 64)\n",
      "    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BG_IOU_THRESHOLD: 0.3\n",
      "    FG_IOU_THRESHOLD: 0.7\n",
      "    FPN_POST_NMS_PER_BATCH: False\n",
      "    FPN_POST_NMS_TOP_N_TEST: 1000\n",
      "    FPN_POST_NMS_TOP_N_TRAIN: 1000\n",
      "    MIN_SIZE: 0\n",
      "    NMS_THRESH: 0.7\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_TOP_N_TEST: 1000\n",
      "    POST_NMS_TOP_N_TRAIN: 1000\n",
      "    PRE_NMS_TOP_N_TEST: 6000\n",
      "    PRE_NMS_TOP_N_TRAIN: 6000\n",
      "    RPN_HEAD: SingleConvRPNHead\n",
      "    RPN_MID_CHANNEL: 256\n",
      "    STRADDLE_THRESH: 0\n",
      "    USE_FPN: True\n",
      "  RPN_ONLY: False\n",
      "  VGG:\n",
      "    VGG16_OUT_CHANNELS: 512\n",
      "  WEIGHT: catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d\n",
      "OUTPUT_DIR: /home/jaleed/Jaleed/SGG/checkpoint/upload_causal_motif_sgdet\n",
      "PATHS_CATALOG: /home/jaleed/Jaleed/SGG/Scene/maskrcnn_benchmark/config/paths_catalog.py\n",
      "PATHS_DATA: /home/jaleed/Jaleed/SGG/Scene/maskrcnn_benchmark/config/../data/datasets\n",
      "SOLVER:\n",
      "  BASE_LR: 0.01\n",
      "  BIAS_LR_FACTOR: 1\n",
      "  CHECKPOINT_PERIOD: 2000\n",
      "  CLIP_NORM: 5.0\n",
      "  GAMMA: 0.1\n",
      "  GRAD_NORM_CLIP: 5.0\n",
      "  IMS_PER_BATCH: 16\n",
      "  MAX_ITER: 40000\n",
      "  MOMENTUM: 0.9\n",
      "  PRE_VAL: True\n",
      "  PRINT_GRAD_FREQ: 4000\n",
      "  SCHEDULE:\n",
      "    COOLDOWN: 0\n",
      "    FACTOR: 0.1\n",
      "    MAX_DECAY_STEP: 3\n",
      "    PATIENCE: 2\n",
      "    THRESHOLD: 0.001\n",
      "    TYPE: WarmupReduceLROnPlateau\n",
      "  STEPS: (10000, 16000)\n",
      "  TO_VAL: True\n",
      "  UPDATE_SCHEDULE_DURING_LOAD: False\n",
      "  VAL_PERIOD: 2000\n",
      "  WARMUP_FACTOR: 0.1\n",
      "  WARMUP_ITERS: 500\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: 0.0\n",
      "TEST:\n",
      "  ALLOW_LOAD_FROM_CACHE: False\n",
      "  BBOX_AUG:\n",
      "    ENABLED: False\n",
      "    H_FLIP: False\n",
      "    MAX_SIZE: 4000\n",
      "    SCALES: ()\n",
      "    SCALE_H_FLIP: False\n",
      "  CUSTUM_EVAL: True\n",
      "  CUSTUM_PATH: /home/jaleed/Jaleed/SGG/temp_dir_inp\n",
      "  DETECTIONS_PER_IMG: 100\n",
      "  EXPECTED_RESULTS: []\n",
      "  EXPECTED_RESULTS_SIGMA_TOL: 4\n",
      "  IMS_PER_BATCH: 1\n",
      "  RELATION:\n",
      "    IOU_THRESHOLD: 0.5\n",
      "    LATER_NMS_PREDICTION_THRES: 0.5\n",
      "    MULTIPLE_PREDS: False\n",
      "    REQUIRE_OVERLAP: False\n",
      "    SYNC_GATHER: True\n",
      "  SAVE_PROPOSALS: False\n",
      "2022-08-10 17:51:55,806 maskrcnn_benchmark INFO: Collecting env info (might take some time)\n",
      "2022-08-10 17:52:01,693 maskrcnn_benchmark INFO: \n",
      "PyTorch version: 1.4.0\n",
      "Is debug build: No\n",
      "CUDA used to build PyTorch: 10.1\n",
      "\n",
      "OS: Ubuntu 18.04.6 LTS\n",
      "GCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
      "CMake version: version 3.10.2\n",
      "\n",
      "Python version: 3.7\n",
      "Is CUDA available: Yes\n",
      "CUDA runtime version: 10.1.105\n",
      "GPU models and configuration: GPU 0: TITAN Xp\n",
      "Nvidia driver version: 440.33.01\n",
      "cuDNN version: Could not collect\n",
      "\n",
      "Versions of relevant libraries:\n",
      "[pip3] numpy==1.21.5\n",
      "[pip3] torch==1.4.0\n",
      "[pip3] torchtext==0.4.0\n",
      "[pip3] torchvision==0.5.0\n",
      "[conda] blas                      1.0                         mkl  \n",
      "[conda] mkl                       2021.4.0           h06a4308_640  \n",
      "[conda] mkl-service               2.4.0            py37h7f8727e_0  \n",
      "[conda] mkl_fft                   1.3.1            py37hd3c417c_0  \n",
      "[conda] mkl_random                1.2.2            py37h51133e4_0  \n",
      "[conda] pytorch                   1.4.0           py3.7_cuda10.1.243_cudnn7.6.3_0    pytorch\n",
      "[conda] torchtext                 0.4.0                    pypi_0    pypi\n",
      "[conda] torchvision               0.5.0                py37_cu101    pytorch\n",
      "        Pillow (9.2.0)\n",
      "2022-08-10 17:52:04,868 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------\n",
      "2022-08-10 17:52:04,868 maskrcnn_benchmark.data.build INFO: get dataset statistics...\n",
      "2022-08-10 17:52:04,868 maskrcnn_benchmark.data.build INFO: Loading data statistics from: /home/jaleed/Jaleed/SGG/checkpoint/upload_causal_motif_sgdet/VG_stanford_filtered_with_attribute_train_statistics.cache\n",
      "2022-08-10 17:52:04,868 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------\n",
      "loading word vectors from /home/jaleed/Jaleed/SGG/glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "loading word vectors from /home/jaleed/Jaleed/SGG/glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "INIT SAVE DIR /home/jaleed/Jaleed/SGG/checkpoint/upload_causal_motif_sgdet\n",
      "get_checkpoint_file /home/jaleed/Jaleed/SGG/checkpoint/upload_causal_motif_sgdet/last_checkpoint\n",
      "last_saved /home/jaleed/Jaleed/SGG/checkpoint/upload_causal_motif_sgdet/model_0028000.pth\n",
      "2022-08-10 17:52:08,002 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from /home/jaleed/Jaleed/SGG/checkpoint/upload_causal_motif_sgdet/model_0028000.pth\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 127.83it/s]\n",
      "=====> /home/jaleed/Jaleed/SGG/temp_dir_out/custom_data_info.json SAVED !\n",
      "2022-08-10 17:52:09,530 maskrcnn_benchmark.inference INFO: Start evaluation on VG_stanford_filtered_with_attribute_test dataset(1 images).\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.11s/it]\n",
      "2022-08-10 17:52:10,668 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.137766 (1.1377663612365723 s / img per device, on 1 devices)\n",
      "2022-08-10 17:52:10,668 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:00.860996 (0.8609955310821533 s / img per device, on 1 devices)\n",
      "=====> /home/jaleed/Jaleed/SGG/temp_dir_out/custom_prediction.json SAVED !\n",
      "/home/jaleed/Jaleed/SGG/Scene\n",
      "2285.jpg\n",
      "2022-08-10 17:52:14,450 maskrcnn_benchmark INFO: Using 1 GPUs\n",
      "2022-08-10 17:52:14,450 maskrcnn_benchmark INFO: AMP_VERBOSE: False\n",
      "DATALOADER:\n",
      "  ASPECT_RATIO_GROUPING: True\n",
      "  NUM_WORKERS: 4\n",
      "  SIZE_DIVISIBILITY: 32\n",
      "DATASETS:\n",
      "  TEST: ('VG_stanford_filtered_with_attribute_test',)\n",
      "  TO_TEST: None\n",
      "  TRAIN: ('VG_stanford_filtered_with_attribute_train',)\n",
      "  VAL: ('VG_stanford_filtered_with_attribute_val',)\n",
      "DETECTED_SGG_DIR: /home/jaleed/Jaleed/SGG/temp_dir_out\n",
      "DTYPE: float16\n",
      "GLOVE_DIR: /home/jaleed/Jaleed/SGG/glove\n",
      "INPUT:\n",
      "  BRIGHTNESS: 0.0\n",
      "  CONTRAST: 0.0\n",
      "  HUE: 0.0\n",
      "  MAX_SIZE_TEST: 1000\n",
      "  MAX_SIZE_TRAIN: 1000\n",
      "  MIN_SIZE_TEST: 600\n",
      "  MIN_SIZE_TRAIN: (600,)\n",
      "  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]\n",
      "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
      "  SATURATION: 0.0\n",
      "  TO_BGR255: True\n",
      "  VERTICAL_FLIP_PROB_TRAIN: 0.0\n",
      "MODEL:\n",
      "  ATTRIBUTE_ON: False\n",
      "  BACKBONE:\n",
      "    CONV_BODY: R-101-FPN\n",
      "    FREEZE_CONV_BODY_AT: 2\n",
      "  CLS_AGNOSTIC_BBOX_REG: False\n",
      "  DEVICE: cuda\n",
      "  FBNET:\n",
      "    ARCH: default\n",
      "    ARCH_DEF: \n",
      "    BN_TYPE: bn\n",
      "    DET_HEAD_BLOCKS: []\n",
      "    DET_HEAD_LAST_SCALE: 1.0\n",
      "    DET_HEAD_STRIDE: 0\n",
      "    DW_CONV_SKIP_BN: True\n",
      "    DW_CONV_SKIP_RELU: True\n",
      "    KPTS_HEAD_BLOCKS: []\n",
      "    KPTS_HEAD_LAST_SCALE: 0.0\n",
      "    KPTS_HEAD_STRIDE: 0\n",
      "    MASK_HEAD_BLOCKS: []\n",
      "    MASK_HEAD_LAST_SCALE: 0.0\n",
      "    MASK_HEAD_STRIDE: 0\n",
      "    RPN_BN_TYPE: \n",
      "    RPN_HEAD_BLOCKS: 0\n",
      "    SCALE_FACTOR: 1.0\n",
      "    WIDTH_DIVISOR: 1\n",
      "  FLIP_AUG: False\n",
      "  FPN:\n",
      "    USE_GN: False\n",
      "    USE_RELU: False\n",
      "  GROUP_NORM:\n",
      "    DIM_PER_GP: -1\n",
      "    EPSILON: 1e-05\n",
      "    NUM_GROUPS: 32\n",
      "  KEYPOINT_ON: False\n",
      "  MASK_ON: False\n",
      "  META_ARCHITECTURE: GeneralizedRCNN\n",
      "  PRETRAINED_DETECTOR_CKPT: /home/jaleed/Jaleed/SGG/checkpoint/upload_causal_motif_sgdet\n",
      "  RELATION_ON: True\n",
      "  RESNETS:\n",
      "    BACKBONE_OUT_CHANNELS: 256\n",
      "    DEFORMABLE_GROUPS: 1\n",
      "    NUM_GROUPS: 32\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    RES5_DILATION: 1\n",
      "    STAGE_WITH_DCN: (False, False, False, False)\n",
      "    STEM_FUNC: StemWithFixedBatchNorm\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "    STRIDE_IN_1X1: False\n",
      "    TRANS_FUNC: BottleneckWithFixedBatchNorm\n",
      "    WIDTH_PER_GROUP: 8\n",
      "    WITH_MODULATED_DCN: False\n",
      "  RETINANET:\n",
      "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
      "    ANCHOR_STRIDES: (8, 16, 32, 64, 128)\n",
      "    ASPECT_RATIOS: (0.5, 1.0, 2.0)\n",
      "    BBOX_REG_BETA: 0.11\n",
      "    BBOX_REG_WEIGHT: 4.0\n",
      "    BG_IOU_THRESHOLD: 0.4\n",
      "    FG_IOU_THRESHOLD: 0.5\n",
      "    INFERENCE_TH: 0.05\n",
      "    LOSS_ALPHA: 0.25\n",
      "    LOSS_GAMMA: 2.0\n",
      "    NMS_TH: 0.4\n",
      "    NUM_CLASSES: 81\n",
      "    NUM_CONVS: 4\n",
      "    OCTAVE: 2.0\n",
      "    PRE_NMS_TOP_N: 1000\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCALES_PER_OCTAVE: 3\n",
      "    STRADDLE_THRESH: 0\n",
      "    USE_C5: True\n",
      "  RETINANET_ON: False\n",
      "  ROI_ATTRIBUTE_HEAD:\n",
      "    ATTRIBUTE_BGFG_RATIO: 3\n",
      "    ATTRIBUTE_BGFG_SAMPLE: True\n",
      "    ATTRIBUTE_LOSS_WEIGHT: 1.0\n",
      "    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor\n",
      "    MAX_ATTRIBUTES: 10\n",
      "    NUM_ATTRIBUTES: 201\n",
      "    POS_WEIGHT: 50.0\n",
      "    PREDICTOR: FPNPredictor\n",
      "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
      "    USE_BINARY_LOSS: True\n",
      "  ROI_BOX_HEAD:\n",
      "    CONV_HEAD_DIM: 256\n",
      "    DILATION: 1\n",
      "    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor\n",
      "    MLP_HEAD_DIM: 4096\n",
      "    NUM_CLASSES: 151\n",
      "    NUM_STACKED_CONVS: 4\n",
      "    POOLER_RESOLUTION: 7\n",
      "    POOLER_SAMPLING_RATIO: 2\n",
      "    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)\n",
      "    PREDICTOR: FPNPredictor\n",
      "    USE_GN: False\n",
      "  ROI_HEADS:\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
      "    BG_IOU_THRESHOLD: 0.3\n",
      "    DETECTIONS_PER_IMG: 80\n",
      "    FG_IOU_THRESHOLD: 0.5\n",
      "    NMS: 0.3\n",
      "    NMS_FILTER_DUPLICATES: True\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_PER_CLS_TOPN: 300\n",
      "    SCORE_THRESH: 0.01\n",
      "    USE_FPN: True\n",
      "  ROI_KEYPOINT_HEAD:\n",
      "    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
      "    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor\n",
      "    MLP_HEAD_DIM: 1024\n",
      "    NUM_CLASSES: 17\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_SCALES: (0.0625,)\n",
      "    PREDICTOR: KeypointRCNNPredictor\n",
      "    RESOLUTION: 14\n",
      "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
      "  ROI_MASK_HEAD:\n",
      "    CONV_LAYERS: (256, 256, 256, 256)\n",
      "    DILATION: 1\n",
      "    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor\n",
      "    MLP_HEAD_DIM: 1024\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_SCALES: (0.0625,)\n",
      "    POSTPROCESS_MASKS: False\n",
      "    POSTPROCESS_MASKS_THRESHOLD: 0.5\n",
      "    PREDICTOR: MaskRCNNC4Predictor\n",
      "    RESOLUTION: 14\n",
      "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
      "    USE_GN: False\n",
      "  ROI_RELATION_HEAD:\n",
      "    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True\n",
      "    BATCH_SIZE_PER_IMAGE: 1024\n",
      "    CAUSAL:\n",
      "      CONTEXT_LAYER: motifs\n",
      "      EFFECT_ANALYSIS: True\n",
      "      EFFECT_TYPE: none\n",
      "      FUSION_TYPE: sum\n",
      "      SEPARATE_SPATIAL: False\n",
      "      SPATIAL_FOR_VISION: True\n",
      "    CONTEXT_DROPOUT_RATE: 0.2\n",
      "    CONTEXT_HIDDEN_DIM: 512\n",
      "    CONTEXT_OBJ_LAYER: 1\n",
      "    CONTEXT_POOLING_DIM: 4096\n",
      "    CONTEXT_REL_LAYER: 1\n",
      "    EMBED_DIM: 200\n",
      "    FEATURE_EXTRACTOR: RelationFeatureExtractor\n",
      "    LABEL_SMOOTHING_LOSS: False\n",
      "    NUM_CLASSES: 51\n",
      "    NUM_SAMPLE_PER_GT_REL: 4\n",
      "    POOLING_ALL_LEVELS: True\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    PREDICTOR: CausalAnalysisPredictor\n",
      "    PREDICT_USE_BIAS: True\n",
      "    PREDICT_USE_VISION: True\n",
      "    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]\n",
      "    REQUIRE_BOX_OVERLAP: False\n",
      "    TRANSFORMER:\n",
      "      DROPOUT_RATE: 0.1\n",
      "      INNER_DIM: 2048\n",
      "      KEY_DIM: 64\n",
      "      NUM_HEAD: 8\n",
      "      OBJ_LAYER: 4\n",
      "      REL_LAYER: 2\n",
      "      VAL_DIM: 64\n",
      "    USE_GT_BOX: False\n",
      "    USE_GT_OBJECT_LABEL: False\n",
      "  RPN:\n",
      "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
      "    ANCHOR_STRIDE: (4, 8, 16, 32, 64)\n",
      "    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BG_IOU_THRESHOLD: 0.3\n",
      "    FG_IOU_THRESHOLD: 0.7\n",
      "    FPN_POST_NMS_PER_BATCH: False\n",
      "    FPN_POST_NMS_TOP_N_TEST: 1000\n",
      "    FPN_POST_NMS_TOP_N_TRAIN: 1000\n",
      "    MIN_SIZE: 0\n",
      "    NMS_THRESH: 0.7\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_TOP_N_TEST: 1000\n",
      "    POST_NMS_TOP_N_TRAIN: 1000\n",
      "    PRE_NMS_TOP_N_TEST: 6000\n",
      "    PRE_NMS_TOP_N_TRAIN: 6000\n",
      "    RPN_HEAD: SingleConvRPNHead\n",
      "    RPN_MID_CHANNEL: 256\n",
      "    STRADDLE_THRESH: 0\n",
      "    USE_FPN: True\n",
      "  RPN_ONLY: False\n",
      "  VGG:\n",
      "    VGG16_OUT_CHANNELS: 512\n",
      "  WEIGHT: catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d\n",
      "OUTPUT_DIR: /home/jaleed/Jaleed/SGG/checkpoint/upload_causal_motif_sgdet\n",
      "PATHS_CATALOG: /home/jaleed/Jaleed/SGG/Scene/maskrcnn_benchmark/config/paths_catalog.py\n",
      "PATHS_DATA: /home/jaleed/Jaleed/SGG/Scene/maskrcnn_benchmark/config/../data/datasets\n",
      "SOLVER:\n",
      "  BASE_LR: 0.01\n",
      "  BIAS_LR_FACTOR: 1\n",
      "  CHECKPOINT_PERIOD: 2000\n",
      "  CLIP_NORM: 5.0\n",
      "  GAMMA: 0.1\n",
      "  GRAD_NORM_CLIP: 5.0\n",
      "  IMS_PER_BATCH: 16\n",
      "  MAX_ITER: 40000\n",
      "  MOMENTUM: 0.9\n",
      "  PRE_VAL: True\n",
      "  PRINT_GRAD_FREQ: 4000\n",
      "  SCHEDULE:\n",
      "    COOLDOWN: 0\n",
      "    FACTOR: 0.1\n",
      "    MAX_DECAY_STEP: 3\n",
      "    PATIENCE: 2\n",
      "    THRESHOLD: 0.001\n",
      "    TYPE: WarmupReduceLROnPlateau\n",
      "  STEPS: (10000, 16000)\n",
      "  TO_VAL: True\n",
      "  UPDATE_SCHEDULE_DURING_LOAD: False\n",
      "  VAL_PERIOD: 2000\n",
      "  WARMUP_FACTOR: 0.1\n",
      "  WARMUP_ITERS: 500\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: 0.0\n",
      "TEST:\n",
      "  ALLOW_LOAD_FROM_CACHE: False\n",
      "  BBOX_AUG:\n",
      "    ENABLED: False\n",
      "    H_FLIP: False\n",
      "    MAX_SIZE: 4000\n",
      "    SCALES: ()\n",
      "    SCALE_H_FLIP: False\n",
      "  CUSTUM_EVAL: True\n",
      "  CUSTUM_PATH: /home/jaleed/Jaleed/SGG/temp_dir_inp\n",
      "  DETECTIONS_PER_IMG: 100\n",
      "  EXPECTED_RESULTS: []\n",
      "  EXPECTED_RESULTS_SIGMA_TOL: 4\n",
      "  IMS_PER_BATCH: 1\n",
      "  RELATION:\n",
      "    IOU_THRESHOLD: 0.5\n",
      "    LATER_NMS_PREDICTION_THRES: 0.5\n",
      "    MULTIPLE_PREDS: False\n",
      "    REQUIRE_OVERLAP: False\n",
      "    SYNC_GATHER: True\n",
      "  SAVE_PROPOSALS: False\n",
      "2022-08-10 17:52:14,451 maskrcnn_benchmark INFO: Collecting env info (might take some time)\n",
      "2022-08-10 17:52:17,765 maskrcnn_benchmark INFO: \n",
      "PyTorch version: 1.4.0\n",
      "Is debug build: No\n",
      "CUDA used to build PyTorch: 10.1\n",
      "\n",
      "OS: Ubuntu 18.04.6 LTS\n",
      "GCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
      "CMake version: version 3.10.2\n",
      "\n",
      "Python version: 3.7\n",
      "Is CUDA available: Yes\n",
      "CUDA runtime version: 10.1.105\n",
      "GPU models and configuration: GPU 0: TITAN Xp\n",
      "Nvidia driver version: 440.33.01\n",
      "cuDNN version: Could not collect\n",
      "\n",
      "Versions of relevant libraries:\n",
      "[pip3] numpy==1.21.5\n",
      "[pip3] torch==1.4.0\n",
      "[pip3] torchtext==0.4.0\n",
      "[pip3] torchvision==0.5.0\n",
      "[conda] blas                      1.0                         mkl  \n",
      "[conda] mkl                       2021.4.0           h06a4308_640  \n",
      "[conda] mkl-service               2.4.0            py37h7f8727e_0  \n",
      "[conda] mkl_fft                   1.3.1            py37hd3c417c_0  \n",
      "[conda] mkl_random                1.2.2            py37h51133e4_0  \n",
      "[conda] pytorch                   1.4.0           py3.7_cuda10.1.243_cudnn7.6.3_0    pytorch\n",
      "[conda] torchtext                 0.4.0                    pypi_0    pypi\n",
      "[conda] torchvision               0.5.0                py37_cu101    pytorch\n",
      "        Pillow (9.2.0)\n",
      "2022-08-10 17:52:20,974 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------\n",
      "2022-08-10 17:52:20,975 maskrcnn_benchmark.data.build INFO: get dataset statistics...\n",
      "2022-08-10 17:52:20,975 maskrcnn_benchmark.data.build INFO: Loading data statistics from: /home/jaleed/Jaleed/SGG/checkpoint/upload_causal_motif_sgdet/VG_stanford_filtered_with_attribute_train_statistics.cache\n",
      "2022-08-10 17:52:20,975 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------\n",
      "loading word vectors from /home/jaleed/Jaleed/SGG/glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "loading word vectors from /home/jaleed/Jaleed/SGG/glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "INIT SAVE DIR /home/jaleed/Jaleed/SGG/checkpoint/upload_causal_motif_sgdet\n",
      "get_checkpoint_file /home/jaleed/Jaleed/SGG/checkpoint/upload_causal_motif_sgdet/last_checkpoint\n",
      "last_saved /home/jaleed/Jaleed/SGG/checkpoint/upload_causal_motif_sgdet/model_0028000.pth\n",
      "2022-08-10 17:52:24,092 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from /home/jaleed/Jaleed/SGG/checkpoint/upload_causal_motif_sgdet/model_0028000.pth\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 82.64it/s]\n",
      "=====> /home/jaleed/Jaleed/SGG/temp_dir_out/custom_data_info.json SAVED !\n",
      "2022-08-10 17:52:25,563 maskrcnn_benchmark.inference INFO: Start evaluation on VG_stanford_filtered_with_attribute_test dataset(1 images).\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.08s/it]\n",
      "2022-08-10 17:52:26,669 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.106525 (1.1065247058868408 s / img per device, on 1 devices)\n",
      "2022-08-10 17:52:26,669 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:00.809717 (0.8097167015075684 s / img per device, on 1 devices)\n",
      "=====> /home/jaleed/Jaleed/SGG/temp_dir_out/custom_prediction.json SAVED !\n",
      "/home/jaleed/Jaleed/SGG/Scene\n",
      "1206.jpg\n",
      "2022-08-10 17:52:30,422 maskrcnn_benchmark INFO: Using 1 GPUs\n",
      "2022-08-10 17:52:30,422 maskrcnn_benchmark INFO: AMP_VERBOSE: False\n",
      "DATALOADER:\n",
      "  ASPECT_RATIO_GROUPING: True\n",
      "  NUM_WORKERS: 4\n",
      "  SIZE_DIVISIBILITY: 32\n",
      "DATASETS:\n",
      "  TEST: ('VG_stanford_filtered_with_attribute_test',)\n",
      "  TO_TEST: None\n",
      "  TRAIN: ('VG_stanford_filtered_with_attribute_train',)\n",
      "  VAL: ('VG_stanford_filtered_with_attribute_val',)\n",
      "DETECTED_SGG_DIR: /home/jaleed/Jaleed/SGG/temp_dir_out\n",
      "DTYPE: float16\n",
      "GLOVE_DIR: /home/jaleed/Jaleed/SGG/glove\n",
      "INPUT:\n",
      "  BRIGHTNESS: 0.0\n",
      "  CONTRAST: 0.0\n",
      "  HUE: 0.0\n",
      "  MAX_SIZE_TEST: 1000\n",
      "  MAX_SIZE_TRAIN: 1000\n",
      "  MIN_SIZE_TEST: 600\n",
      "  MIN_SIZE_TRAIN: (600,)\n",
      "  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]\n",
      "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
      "  SATURATION: 0.0\n",
      "  TO_BGR255: True\n",
      "  VERTICAL_FLIP_PROB_TRAIN: 0.0\n",
      "MODEL:\n",
      "  ATTRIBUTE_ON: False\n",
      "  BACKBONE:\n",
      "    CONV_BODY: R-101-FPN\n",
      "    FREEZE_CONV_BODY_AT: 2\n",
      "  CLS_AGNOSTIC_BBOX_REG: False\n",
      "  DEVICE: cuda\n",
      "  FBNET:\n",
      "    ARCH: default\n",
      "    ARCH_DEF: \n",
      "    BN_TYPE: bn\n",
      "    DET_HEAD_BLOCKS: []\n",
      "    DET_HEAD_LAST_SCALE: 1.0\n",
      "    DET_HEAD_STRIDE: 0\n",
      "    DW_CONV_SKIP_BN: True\n",
      "    DW_CONV_SKIP_RELU: True\n",
      "    KPTS_HEAD_BLOCKS: []\n",
      "    KPTS_HEAD_LAST_SCALE: 0.0\n",
      "    KPTS_HEAD_STRIDE: 0\n",
      "    MASK_HEAD_BLOCKS: []\n",
      "    MASK_HEAD_LAST_SCALE: 0.0\n",
      "    MASK_HEAD_STRIDE: 0\n",
      "    RPN_BN_TYPE: \n",
      "    RPN_HEAD_BLOCKS: 0\n",
      "    SCALE_FACTOR: 1.0\n",
      "    WIDTH_DIVISOR: 1\n",
      "  FLIP_AUG: False\n",
      "  FPN:\n",
      "    USE_GN: False\n",
      "    USE_RELU: False\n",
      "  GROUP_NORM:\n",
      "    DIM_PER_GP: -1\n",
      "    EPSILON: 1e-05\n",
      "    NUM_GROUPS: 32\n",
      "  KEYPOINT_ON: False\n",
      "  MASK_ON: False\n",
      "  META_ARCHITECTURE: GeneralizedRCNN\n",
      "  PRETRAINED_DETECTOR_CKPT: /home/jaleed/Jaleed/SGG/checkpoint/upload_causal_motif_sgdet\n",
      "  RELATION_ON: True\n",
      "  RESNETS:\n",
      "    BACKBONE_OUT_CHANNELS: 256\n",
      "    DEFORMABLE_GROUPS: 1\n",
      "    NUM_GROUPS: 32\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    RES5_DILATION: 1\n",
      "    STAGE_WITH_DCN: (False, False, False, False)\n",
      "    STEM_FUNC: StemWithFixedBatchNorm\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "    STRIDE_IN_1X1: False\n",
      "    TRANS_FUNC: BottleneckWithFixedBatchNorm\n",
      "    WIDTH_PER_GROUP: 8\n",
      "    WITH_MODULATED_DCN: False\n",
      "  RETINANET:\n",
      "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
      "    ANCHOR_STRIDES: (8, 16, 32, 64, 128)\n",
      "    ASPECT_RATIOS: (0.5, 1.0, 2.0)\n",
      "    BBOX_REG_BETA: 0.11\n",
      "    BBOX_REG_WEIGHT: 4.0\n",
      "    BG_IOU_THRESHOLD: 0.4\n",
      "    FG_IOU_THRESHOLD: 0.5\n",
      "    INFERENCE_TH: 0.05\n",
      "    LOSS_ALPHA: 0.25\n",
      "    LOSS_GAMMA: 2.0\n",
      "    NMS_TH: 0.4\n",
      "    NUM_CLASSES: 81\n",
      "    NUM_CONVS: 4\n",
      "    OCTAVE: 2.0\n",
      "    PRE_NMS_TOP_N: 1000\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCALES_PER_OCTAVE: 3\n",
      "    STRADDLE_THRESH: 0\n",
      "    USE_C5: True\n",
      "  RETINANET_ON: False\n",
      "  ROI_ATTRIBUTE_HEAD:\n",
      "    ATTRIBUTE_BGFG_RATIO: 3\n",
      "    ATTRIBUTE_BGFG_SAMPLE: True\n",
      "    ATTRIBUTE_LOSS_WEIGHT: 1.0\n",
      "    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor\n",
      "    MAX_ATTRIBUTES: 10\n",
      "    NUM_ATTRIBUTES: 201\n",
      "    POS_WEIGHT: 50.0\n",
      "    PREDICTOR: FPNPredictor\n",
      "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
      "    USE_BINARY_LOSS: True\n",
      "  ROI_BOX_HEAD:\n",
      "    CONV_HEAD_DIM: 256\n",
      "    DILATION: 1\n",
      "    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor\n",
      "    MLP_HEAD_DIM: 4096\n",
      "    NUM_CLASSES: 151\n",
      "    NUM_STACKED_CONVS: 4\n",
      "    POOLER_RESOLUTION: 7\n",
      "    POOLER_SAMPLING_RATIO: 2\n",
      "    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)\n",
      "    PREDICTOR: FPNPredictor\n",
      "    USE_GN: False\n",
      "  ROI_HEADS:\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
      "    BG_IOU_THRESHOLD: 0.3\n",
      "    DETECTIONS_PER_IMG: 80\n",
      "    FG_IOU_THRESHOLD: 0.5\n",
      "    NMS: 0.3\n",
      "    NMS_FILTER_DUPLICATES: True\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_PER_CLS_TOPN: 300\n",
      "    SCORE_THRESH: 0.01\n",
      "    USE_FPN: True\n",
      "  ROI_KEYPOINT_HEAD:\n",
      "    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
      "    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor\n",
      "    MLP_HEAD_DIM: 1024\n",
      "    NUM_CLASSES: 17\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_SCALES: (0.0625,)\n",
      "    PREDICTOR: KeypointRCNNPredictor\n",
      "    RESOLUTION: 14\n",
      "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
      "  ROI_MASK_HEAD:\n",
      "    CONV_LAYERS: (256, 256, 256, 256)\n",
      "    DILATION: 1\n",
      "    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor\n",
      "    MLP_HEAD_DIM: 1024\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_SCALES: (0.0625,)\n",
      "    POSTPROCESS_MASKS: False\n",
      "    POSTPROCESS_MASKS_THRESHOLD: 0.5\n",
      "    PREDICTOR: MaskRCNNC4Predictor\n",
      "    RESOLUTION: 14\n",
      "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
      "    USE_GN: False\n",
      "  ROI_RELATION_HEAD:\n",
      "    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True\n",
      "    BATCH_SIZE_PER_IMAGE: 1024\n",
      "    CAUSAL:\n",
      "      CONTEXT_LAYER: motifs\n",
      "      EFFECT_ANALYSIS: True\n",
      "      EFFECT_TYPE: none\n",
      "      FUSION_TYPE: sum\n",
      "      SEPARATE_SPATIAL: False\n",
      "      SPATIAL_FOR_VISION: True\n",
      "    CONTEXT_DROPOUT_RATE: 0.2\n",
      "    CONTEXT_HIDDEN_DIM: 512\n",
      "    CONTEXT_OBJ_LAYER: 1\n",
      "    CONTEXT_POOLING_DIM: 4096\n",
      "    CONTEXT_REL_LAYER: 1\n",
      "    EMBED_DIM: 200\n",
      "    FEATURE_EXTRACTOR: RelationFeatureExtractor\n",
      "    LABEL_SMOOTHING_LOSS: False\n",
      "    NUM_CLASSES: 51\n",
      "    NUM_SAMPLE_PER_GT_REL: 4\n",
      "    POOLING_ALL_LEVELS: True\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    PREDICTOR: CausalAnalysisPredictor\n",
      "    PREDICT_USE_BIAS: True\n",
      "    PREDICT_USE_VISION: True\n",
      "    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]\n",
      "    REQUIRE_BOX_OVERLAP: False\n",
      "    TRANSFORMER:\n",
      "      DROPOUT_RATE: 0.1\n",
      "      INNER_DIM: 2048\n",
      "      KEY_DIM: 64\n",
      "      NUM_HEAD: 8\n",
      "      OBJ_LAYER: 4\n",
      "      REL_LAYER: 2\n",
      "      VAL_DIM: 64\n",
      "    USE_GT_BOX: False\n",
      "    USE_GT_OBJECT_LABEL: False\n",
      "  RPN:\n",
      "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
      "    ANCHOR_STRIDE: (4, 8, 16, 32, 64)\n",
      "    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BG_IOU_THRESHOLD: 0.3\n",
      "    FG_IOU_THRESHOLD: 0.7\n",
      "    FPN_POST_NMS_PER_BATCH: False\n",
      "    FPN_POST_NMS_TOP_N_TEST: 1000\n",
      "    FPN_POST_NMS_TOP_N_TRAIN: 1000\n",
      "    MIN_SIZE: 0\n",
      "    NMS_THRESH: 0.7\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_TOP_N_TEST: 1000\n",
      "    POST_NMS_TOP_N_TRAIN: 1000\n",
      "    PRE_NMS_TOP_N_TEST: 6000\n",
      "    PRE_NMS_TOP_N_TRAIN: 6000\n",
      "    RPN_HEAD: SingleConvRPNHead\n",
      "    RPN_MID_CHANNEL: 256\n",
      "    STRADDLE_THRESH: 0\n",
      "    USE_FPN: True\n",
      "  RPN_ONLY: False\n",
      "  VGG:\n",
      "    VGG16_OUT_CHANNELS: 512\n",
      "  WEIGHT: catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d\n",
      "OUTPUT_DIR: /home/jaleed/Jaleed/SGG/checkpoint/upload_causal_motif_sgdet\n",
      "PATHS_CATALOG: /home/jaleed/Jaleed/SGG/Scene/maskrcnn_benchmark/config/paths_catalog.py\n",
      "PATHS_DATA: /home/jaleed/Jaleed/SGG/Scene/maskrcnn_benchmark/config/../data/datasets\n",
      "SOLVER:\n",
      "  BASE_LR: 0.01\n",
      "  BIAS_LR_FACTOR: 1\n",
      "  CHECKPOINT_PERIOD: 2000\n",
      "  CLIP_NORM: 5.0\n",
      "  GAMMA: 0.1\n",
      "  GRAD_NORM_CLIP: 5.0\n",
      "  IMS_PER_BATCH: 16\n",
      "  MAX_ITER: 40000\n",
      "  MOMENTUM: 0.9\n",
      "  PRE_VAL: True\n",
      "  PRINT_GRAD_FREQ: 4000\n",
      "  SCHEDULE:\n",
      "    COOLDOWN: 0\n",
      "    FACTOR: 0.1\n",
      "    MAX_DECAY_STEP: 3\n",
      "    PATIENCE: 2\n",
      "    THRESHOLD: 0.001\n",
      "    TYPE: WarmupReduceLROnPlateau\n",
      "  STEPS: (10000, 16000)\n",
      "  TO_VAL: True\n",
      "  UPDATE_SCHEDULE_DURING_LOAD: False\n",
      "  VAL_PERIOD: 2000\n",
      "  WARMUP_FACTOR: 0.1\n",
      "  WARMUP_ITERS: 500\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: 0.0\n",
      "TEST:\n",
      "  ALLOW_LOAD_FROM_CACHE: False\n",
      "  BBOX_AUG:\n",
      "    ENABLED: False\n",
      "    H_FLIP: False\n",
      "    MAX_SIZE: 4000\n",
      "    SCALES: ()\n",
      "    SCALE_H_FLIP: False\n",
      "  CUSTUM_EVAL: True\n",
      "  CUSTUM_PATH: /home/jaleed/Jaleed/SGG/temp_dir_inp\n",
      "  DETECTIONS_PER_IMG: 100\n",
      "  EXPECTED_RESULTS: []\n",
      "  EXPECTED_RESULTS_SIGMA_TOL: 4\n",
      "  IMS_PER_BATCH: 1\n",
      "  RELATION:\n",
      "    IOU_THRESHOLD: 0.5\n",
      "    LATER_NMS_PREDICTION_THRES: 0.5\n",
      "    MULTIPLE_PREDS: False\n",
      "    REQUIRE_OVERLAP: False\n",
      "    SYNC_GATHER: True\n",
      "  SAVE_PROPOSALS: False\n",
      "2022-08-10 17:52:30,423 maskrcnn_benchmark INFO: Collecting env info (might take some time)\n",
      "2022-08-10 17:52:33,798 maskrcnn_benchmark INFO: \n",
      "PyTorch version: 1.4.0\n",
      "Is debug build: No\n",
      "CUDA used to build PyTorch: 10.1\n",
      "\n",
      "OS: Ubuntu 18.04.6 LTS\n",
      "GCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
      "CMake version: version 3.10.2\n",
      "\n",
      "Python version: 3.7\n",
      "Is CUDA available: Yes\n",
      "CUDA runtime version: 10.1.105\n",
      "GPU models and configuration: GPU 0: TITAN Xp\n",
      "Nvidia driver version: 440.33.01\n",
      "cuDNN version: Could not collect\n",
      "\n",
      "Versions of relevant libraries:\n",
      "[pip3] numpy==1.21.5\n",
      "[pip3] torch==1.4.0\n",
      "[pip3] torchtext==0.4.0\n",
      "[pip3] torchvision==0.5.0\n",
      "[conda] blas                      1.0                         mkl  \n",
      "[conda] mkl                       2021.4.0           h06a4308_640  \n",
      "[conda] mkl-service               2.4.0            py37h7f8727e_0  \n",
      "[conda] mkl_fft                   1.3.1            py37hd3c417c_0  \n",
      "[conda] mkl_random                1.2.2            py37h51133e4_0  \n",
      "[conda] pytorch                   1.4.0           py3.7_cuda10.1.243_cudnn7.6.3_0    pytorch\n",
      "[conda] torchtext                 0.4.0                    pypi_0    pypi\n",
      "[conda] torchvision               0.5.0                py37_cu101    pytorch\n",
      "        Pillow (9.2.0)\n",
      "2022-08-10 17:52:36,992 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------\n",
      "2022-08-10 17:52:36,992 maskrcnn_benchmark.data.build INFO: get dataset statistics...\n",
      "2022-08-10 17:52:36,992 maskrcnn_benchmark.data.build INFO: Loading data statistics from: /home/jaleed/Jaleed/SGG/checkpoint/upload_causal_motif_sgdet/VG_stanford_filtered_with_attribute_train_statistics.cache\n",
      "2022-08-10 17:52:36,992 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------\n",
      "loading word vectors from /home/jaleed/Jaleed/SGG/glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "loading word vectors from /home/jaleed/Jaleed/SGG/glove/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "INIT SAVE DIR /home/jaleed/Jaleed/SGG/checkpoint/upload_causal_motif_sgdet\n",
      "get_checkpoint_file /home/jaleed/Jaleed/SGG/checkpoint/upload_causal_motif_sgdet/last_checkpoint\n",
      "last_saved /home/jaleed/Jaleed/SGG/checkpoint/upload_causal_motif_sgdet/model_0028000.pth\n",
      "2022-08-10 17:52:40,028 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from /home/jaleed/Jaleed/SGG/checkpoint/upload_causal_motif_sgdet/model_0028000.pth\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 136.85it/s]\n",
      "=====> /home/jaleed/Jaleed/SGG/temp_dir_out/custom_data_info.json SAVED !\n",
      "2022-08-10 17:52:41,458 maskrcnn_benchmark.inference INFO: Start evaluation on VG_stanford_filtered_with_attribute_test dataset(1 images).\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.07s/it]\n",
      "2022-08-10 17:52:42,562 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.103885 (1.1038854122161865 s / img per device, on 1 devices)\n",
      "2022-08-10 17:52:42,562 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:00.813602 (0.8136024475097656 s / img per device, on 1 devices)\n",
      "=====> /home/jaleed/Jaleed/SGG/temp_dir_out/custom_prediction.json SAVED !\n",
      "/home/jaleed/Jaleed/SGG/Scene\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "import sys\n",
    "import torch\n",
    "import h5py\n",
    "import json\n",
    "import shutil\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from maskrcnn_benchmark.structures.bounding_box import BoxList\n",
    "from maskrcnn_benchmark.structures.boxlist_ops import boxlist_iou\n",
    "eval_inp_img = '/home/jaleed/Jaleed/Eval_IO/vg/0_images' \n",
    "eval_outp_sg = '/home/jaleed/Jaleed/Eval_IO/vg/1_pred_scene_graphs'\n",
    "%cd /home/jaleed/Jaleed/SGG/Scene\n",
    "\n",
    "for img_file in os.listdir(eval_inp_img):\n",
    "    if os.path.isdir(eval_outp_sg+'/'+img_file)==False:      \n",
    "        print(img_file)\n",
    "        # clear SGG input folder\n",
    "        !rm -r /home/jaleed/Jaleed/SGG/temp_dir_inp\n",
    "        os.mkdir('/home/jaleed/Jaleed/SGG/temp_dir_inp')\n",
    "        # copy image to SGG input directory from eval_inp_img directory\n",
    "        shutil.copyfile(eval_inp_img+'/'+img_file, '/home/jaleed/Jaleed/SGG/temp_dir_inp/'+img_file)\n",
    "        # run SGG\n",
    "        !(CUDA_VISIBLE_DEVICES=0 python -m torch.distributed.launch --master_port 10027 --nproc_per_node=1 tools/relation_test_net.py \\\n",
    "            --config-file \"configs/e2e_relation_X_101_32_8_FPN_1x.yaml\" \\\n",
    "            MODEL.ROI_RELATION_HEAD.USE_GT_BOX False \\\n",
    "            MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL False \\\n",
    "            MODEL.ROI_RELATION_HEAD.PREDICTOR CausalAnalysisPredictor \\\n",
    "            MODEL.ROI_RELATION_HEAD.CAUSAL.EFFECT_TYPE none \\\n",
    "            MODEL.ROI_RELATION_HEAD.CAUSAL.FUSION_TYPE sum \\\n",
    "            MODEL.ROI_RELATION_HEAD.CAUSAL.CONTEXT_LAYER motifs \\\n",
    "            TEST.IMS_PER_BATCH 1 DTYPE \"float16\" \\\n",
    "            GLOVE_DIR /home/jaleed/Jaleed/SGG/glove \\\n",
    "            MODEL.PRETRAINED_DETECTOR_CKPT /home/jaleed/Jaleed/SGG/checkpoint/upload_causal_motif_sgdet \\\n",
    "            OUTPUT_DIR /home/jaleed/Jaleed/SGG/checkpoint/upload_causal_motif_sgdet \\\n",
    "            TEST.CUSTUM_EVAL True \\\n",
    "            TEST.CUSTUM_PATH /home/jaleed/Jaleed/SGG/temp_dir_inp \\\n",
    "            DETECTED_SGG_DIR /home/jaleed/Jaleed/SGG/temp_dir_out)\n",
    "        # copy result from SGG output directory to eval_outp_sg directory\n",
    "        shutil.copytree('/home/jaleed/Jaleed/SGG/temp_dir_out', eval_outp_sg+'/'+img_file)\n",
    "        \n",
    "        # reset (to avoid mem/IO error) and repeat imports and variables after reset \n",
    "        %reset -f\n",
    "        import os\n",
    "        import copy\n",
    "        import sys\n",
    "        import torch\n",
    "        import h5py\n",
    "        import json\n",
    "        import shutil\n",
    "        from matplotlib.pyplot import imshow\n",
    "        from PIL import Image, ImageDraw\n",
    "        import numpy as np\n",
    "        from collections import defaultdict\n",
    "        from tqdm import tqdm\n",
    "        import random\n",
    "        from maskrcnn_benchmark.structures.bounding_box import BoxList\n",
    "        from maskrcnn_benchmark.structures.boxlist_ops import boxlist_iou\n",
    "        eval_inp_img = '/home/jaleed/Jaleed/Eval_IO/vg/0_images' #repeat for vg, flickr and coco\n",
    "        eval_outp_sg = '/home/jaleed/Jaleed/Eval_IO/vg/1_pred_scene_graphs'\n",
    "        %cd /home/jaleed/Jaleed/SGG/Scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a9fbfa-6aa4-40c2-86b7-e8eeabfe7084",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import sys\n",
    "import torch\n",
    "import h5py\n",
    "import json\n",
    "import shutil\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from maskrcnn_benchmark.structures.bounding_box import BoxList\n",
    "from maskrcnn_benchmark.structures.boxlist_ops import boxlist_iou\n",
    "eval_inp_img = '/home/jaleed/Jaleed/Eval_IO_1000/coco/0_images' #repeat for vg, flickr and coco\n",
    "eval_outp_sg = '/home/jaleed/Jaleed/Eval_IO_1000/coco/1_pred_scene_graphs'\n",
    "%cd /home/jaleed/Jaleed/SGG/Scene\n",
    "\n",
    "for img_file in os.listdir(eval_inp_img):\n",
    "    if os.path.isdir(eval_outp_sg+'/'+img_file)==False:      \n",
    "        print(img_file)\n",
    "        # clear SGG input folder\n",
    "        !rm -r /home/jaleed/Jaleed/SGG/temp_dir_inp\n",
    "        os.mkdir('/home/jaleed/Jaleed/SGG/temp_dir_inp')\n",
    "        # copy image to SGG input directory from eval_inp_img directory\n",
    "        shutil.copyfile(eval_inp_img+'/'+img_file, '/home/jaleed/Jaleed/SGG/temp_dir_inp/'+img_file)\n",
    "        # run SGG\n",
    "        !(CUDA_VISIBLE_DEVICES=0 python -m torch.distributed.launch --master_port 10027 --nproc_per_node=1 tools/relation_test_net.py \\\n",
    "            --config-file \"configs/e2e_relation_X_101_32_8_FPN_1x.yaml\" \\\n",
    "            MODEL.ROI_RELATION_HEAD.USE_GT_BOX False \\\n",
    "            MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL False \\\n",
    "            MODEL.ROI_RELATION_HEAD.PREDICTOR CausalAnalysisPredictor \\\n",
    "            MODEL.ROI_RELATION_HEAD.CAUSAL.EFFECT_TYPE none \\\n",
    "            MODEL.ROI_RELATION_HEAD.CAUSAL.FUSION_TYPE sum \\\n",
    "            MODEL.ROI_RELATION_HEAD.CAUSAL.CONTEXT_LAYER motifs \\\n",
    "            TEST.IMS_PER_BATCH 1 DTYPE \"float16\" \\\n",
    "            GLOVE_DIR /home/jaleed/Jaleed/SGG/glove \\\n",
    "            MODEL.PRETRAINED_DETECTOR_CKPT /home/jaleed/Jaleed/SGG/checkpoint/upload_causal_motif_sgdet \\\n",
    "            OUTPUT_DIR /home/jaleed/Jaleed/SGG/checkpoint/upload_causal_motif_sgdet \\\n",
    "            TEST.CUSTUM_EVAL True \\\n",
    "            TEST.CUSTUM_PATH /home/jaleed/Jaleed/SGG/temp_dir_inp \\\n",
    "            DETECTED_SGG_DIR /home/jaleed/Jaleed/SGG/temp_dir_out)\n",
    "        # copy result from SGG output directory to eval_outp_sg directory\n",
    "        shutil.copytree('/home/jaleed/Jaleed/SGG/temp_dir_out', eval_outp_sg+'/'+img_file)\n",
    "        \n",
    "        # reset (to avoid mem/IO error) and repeat imports and variables after reset \n",
    "        %reset -f\n",
    "        import os\n",
    "        import copy\n",
    "        import sys\n",
    "        import torch\n",
    "        import h5py\n",
    "        import json\n",
    "        import shutil\n",
    "        from matplotlib.pyplot import imshow\n",
    "        from PIL import Image, ImageDraw\n",
    "        import numpy as np\n",
    "        from collections import defaultdict\n",
    "        from tqdm import tqdm\n",
    "        import random\n",
    "        from maskrcnn_benchmark.structures.bounding_box import BoxList\n",
    "        from maskrcnn_benchmark.structures.boxlist_ops import boxlist_iou\n",
    "        eval_inp_img = '/home/jaleed/Jaleed/Eval_IO_1000/coco/0_images' #repeat for vg, flickr and coco\n",
    "        eval_outp_sg = '/home/jaleed/Jaleed/Eval_IO_1000/coco/1_pred_scene_graphs'\n",
    "        %cd /home/jaleed/Jaleed/SGG/Scene"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd9c054-21d0-48fd-b80c-83cc1465474c",
   "metadata": {},
   "source": [
    "Next:\n",
    "   - Back to CSKG env\n",
    "   - SGG-CSKG save two versions of enriched SGs: (1) without CSKG max N = 1 in enrich_vg; (2) with CSKG max N = 5 in enrich_vg; (current)\n",
    "   - Try: Update both to add new preds at 0th, 21st and 51st place as per requirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15dbf98-cb65-4cf7-98e5-27bfbcb2d804",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
